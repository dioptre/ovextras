# Basic Template Test for automatic run a scenario that produce a file to be compared to a reference file
# You need to set the name of the test according to name of scenario file and reference file

# Test Hilbert transform Box

SET(TEST_NAME "HilbertTransform")
SET(SCENARIO_TO_TEST "${TEST_NAME}.xml")

# These three tests are not yet working correctly...
# SET(SUBTEST1_NAME "hilbert")
# SET(SUBTEST2_NAME "phase")
# SET(SUBTEST3_NAME "envelope")

IF(WIN32)
	SET(EXT cmd)
	SET(OS_FLAGS "--no-pause")
	SET(OV_LOGFILE "$ENV{APPDATA}/openvibe/log/openvibe-designer.log")	
ELSE(WIN32)
	SET(EXT sh)
	SET(OS_FLAGS "")
	SET(OV_LOGFILE "$ENV{HOME}/.config/openvibe/log/openvibe-designer.log")	
ENDIF(WIN32)

ADD_TEST(clean_${TEST_NAME} "rm" "-f" "${SUBTEST1_NAME}.csv" "${SUBTEST2_NAME}.csv" "${SUBTEST3_NAME}.csv")
ADD_TEST(run_${TEST_NAME} "$ENV{OV_BINARY_PATH}/openvibe-designer.${EXT}" ${OS_FLAGS} "--no-session-management" "--no-gui" "--play" ${SCENARIO_TO_TEST})
# ADD_TEST(compare_${SUBTEST1_NAME} "$ENV{OV_BINARY_PATH}/test_thresholdDataComparison.${EXT}" ${OS_FLAGS} "${SUBTEST1_NAME}_${TEST_NAME}.csv" "${SUBTEST1_NAME}_${TEST_NAME}.ref.csv" 0.1)
# ADD_TEST(compare_${SUBTEST2_NAME} "$ENV{OV_BINARY_PATH}/test_thresholdDataComparison.${EXT}" ${OS_FLAGS} "${SUBTEST2_NAME}_${TEST_NAME}.csv" "${SUBTEST2_NAME}_${TEST_NAME}.ref.csv" 0.1)
# ADD_TEST(compare_${SUBTEST3_NAME} "$ENV{OV_BINARY_PATH}/test_thresholdDataComparison.${EXT}" ${OS_FLAGS} "${SUBTEST3_NAME}_${TEST_NAME}.csv" "${SUBTEST3_NAME}_${TEST_NAME}.ref.csv" 0.1)

## add some properties that help to debug
IF(WIN32)
	SET_TESTS_PROPERTIES(run_${TEST_NAME} PROPERTIES ATTACHED_FILES_ON_FAIL "$ENV{APPDATA}/openvibe/log/openvibe-designer.log")
ELSE(WIN32)
	SET_TESTS_PROPERTIES(run_${TEST_NAME} PROPERTIES ATTACHED_FILES_ON_FAIL "$ENV{HOME}/.config/openvibe/log/openvibe-designer.log")
ENDIF(WIN32)

#SET_TESTS_PROPERTIES(compare_${SUBTEST1_NAME} PROPERTIES ATTACHED_FILES_ON_FAIL "${SUBTEST1_NAME}.csv")
#SET_TESTS_PROPERTIES(compare_${SUBTEST2_NAME} PROPERTIES ATTACHED_FILES_ON_FAIL "${SUBTEST2_NAME}.csv")
#SET_TESTS_PROPERTIES(compare_${SUBTEST3_NAME} PROPERTIES ATTACHED_FILES_ON_FAIL "${SUBTEST3_NAME}.csv")
#SET_TESTS_PROPERTIES(compare_${SUBTEST1_NAME} compare_${SUBTEST2_NAME} compare_${SUBTEST3_NAME} PROPERTIES DEPENDS run_${TEST_NAME})
#SET_TESTS_PROPERTIES(run_${TEST_NAME} PROPERTIES DEPENDS clean_${TEST_NAME})



# Test Connectivity Box - PLV algorithm

#SET(TEST_NAME "PhaseLockingValue")
#SET(SCENARIO_TO_TEST "${TEST_NAME}.xml")

#ADD_TEST(clean_${TEST_NAME} "rm" "-f" "${TEST_NAME}.csv")
#ADD_TEST(run_${TEST_NAME} "$ENV{OV_BINARY_PATH}/openvibe-designer.${EXT}" ${OS_FLAGS} "--no-session-management" "--no-gui" "--play" ${SCENARIO_TO_TEST})
#ADD_TEST(compare_${TEST_NAME} "$ENV{OV_BINARY_PATH}/test_thresholdDataComparison.${EXT}" ${OS_FLAGS} "${TEST_NAME}.csv" "${TEST_NAME}.ref.csv" 0.1)

## add some properties that help to debug
#IF(WIN32)
#	SET_TESTS_PROPERTIES(run_${TEST_NAME} PROPERTIES ATTACHED_FILES_ON_FAIL "$ENV{APPDATA}/openvibe/log/openvibe-designer.log")
#ELSE(WIN32)
#	SET_TESTS_PROPERTIES(run_${TEST_NAME} PROPERTIES ATTACHED_FILES_ON_FAIL "$ENV{HOME}/.config/openvibe/log/openvibe-designer.log")
#ENDIF(WIN32)

#SET_TESTS_PROPERTIES(compare_${TEST_NAME} PROPERTIES ATTACHED_FILES_ON_FAIL "${TEST_NAME}.csv")
#SET_TESTS_PROPERTIES(compare_${TEST_NAME} PROPERTIES DEPENDS run_${TEST_NAME})
#SET_TESTS_PROPERTIES(run_${TEST_NAME} PROPERTIES DEPENDS clean_${TEST_NAME})



# Test Auto-Regressive model

SET(TEST_NAME "ARFeatures")
SET(SCENARIO_TO_TEST "${TEST_NAME}.xml")

ADD_TEST(clean_${TEST_NAME} "rm" "-f" "${TEST_NAME}.csv")
ADD_TEST(run_${TEST_NAME} "$ENV{OV_BINARY_PATH}/openvibe-designer.${EXT}" ${OS_FLAGS} "--no-session-management" "--no-gui" "--play" ${SCENARIO_TO_TEST})
ADD_TEST(compare_${TEST_NAME} "$ENV{OV_BINARY_PATH}/test_thresholdDataComparison.${EXT}" ${OS_FLAGS} "${TEST_NAME}.csv" "${TEST_NAME}.ref.csv" 0.1)

## add some properties that help to debug
IF(WIN32)
	SET_TESTS_PROPERTIES(run_${TEST_NAME} PROPERTIES ATTACHED_FILES_ON_FAIL "$ENV{APPDATA}/openvibe/log/openvibe-designer.log")
ELSE(WIN32)
	SET_TESTS_PROPERTIES(run_${TEST_NAME} PROPERTIES ATTACHED_FILES_ON_FAIL "$ENV{HOME}/.config/openvibe/log/openvibe-designer.log")
ENDIF(WIN32)

SET_TESTS_PROPERTIES(compare_${TEST_NAME} PROPERTIES ATTACHED_FILES_ON_FAIL "${TEST_NAME}.csv")
SET_TESTS_PROPERTIES(compare_${TEST_NAME} PROPERTIES DEPENDS run_${TEST_NAME})
SET_TESTS_PROPERTIES(run_${TEST_NAME} PROPERTIES DEPENDS clean_${TEST_NAME})


### Do not enable the commented out sikuli tests unless you 
### or your lab commits to keep them passing in the long term.
#FIND_PROGRAM(SIKULI NAMES sikuli-ide)
#IF(SIKULI)
#	IF(UNIX)
#		ADD_TEST(sikuli_crop "${SIKULI}" -t testCrop.UNIX.sikuli)
#	ENDIF(UNIX)
#ENDIF(SIKULI)

# Test Regularized CSP

SET(TEST_SCENARIOS "RegularizedCSP_None" "RegularizedCSP_Tikhonov" "RegularizedCSP_Shrink" "RegularizedCSP_Both")
SET(TEST_SHRINKS    0.0 0.0 0.9 0.5)
SET(TEST_TIKHONOVS  0.0 0.9 0.0 0.5)
SET(TEST_THRESHOLDS  50  70  70  70)

FOREACH(TEST_NAME ${TEST_SCENARIOS})

	ADD_TEST(clean_${TEST_NAME} rm -f ${OV_LOGFILE} output-${TEST_NAME}.txt)

	LIST(GET TEST_SHRINKS 0 PARAM_SHRINK)	
	LIST(GET TEST_TIKHONOVS 0 PARAM_TIKHONOV)
	LIST(GET TEST_THRESHOLDS 0 COMPARE_THRESHOLD)	
	
	ADD_TEST(run_${TEST_NAME}_Train "$ENV{OV_BINARY_PATH}/openvibe-designer.${EXT}" ${OS_FLAGS} "--no-gui"  "--no-session-management" "--config" "$ENV{OV_BINARY_PATH}/share/openvibe/kernel/openvibe_test.conf"  --random-seed 123 --define TEST_TIKHONOV ${PARAM_TIKHONOV} --define TEST_SHRINK ${PARAM_SHRINK} --define TEST_FILTER output-${TEST_NAME}.txt  "--play-fast" "test-regularizedcsp-train.xml")	
	
	ADD_TEST(run_${TEST_NAME}_Test "$ENV{OV_BINARY_PATH}/openvibe-designer.${EXT}" ${OS_FLAGS} "--no-gui"  "--no-session-management" "--config" "$ENV{OV_BINARY_PATH}/share/openvibe/kernel/openvibe_test.conf" --random-seed 456 --define TEST_FILTER output-${TEST_NAME}.txt "--play-fast" "test-regularizedcsp-test.xml")
	
	ADD_TEST(compare_${TEST_NAME} "$ENV{OV_BINARY_PATH}/test_accuracy.${EXT}" "${OS_FLAGS}" "${OV_LOGFILE}" ${COMPARE_THRESHOLD})

	# It would be better to clean last, but we can't do this as it will delete the 
	# output we wish to include, and we can't prevent clean from running if a prev. test fails
	# We need the clean to be sure that the comparator stage is not getting data from a previous run.
	SET_TESTS_PROPERTIES(run_${TEST_NAME}_Train PROPERTIES DEPENDS clean_${TEST_NAME})
	SET_TESTS_PROPERTIES(run_${TEST_NAME}_Train PROPERTIES ATTACHED_FILES_ON_FAIL ${OV_LOGFILE})
	
	SET_TESTS_PROPERTIES(run_${TEST_NAME}_Test PROPERTIES DEPENDS run_${TEST_NAME}_Train)	
	SET_TESTS_PROPERTIES(run_${TEST_NAME}_Test PROPERTIES ATTACHED_FILES_ON_FAIL ${OV_LOGFILE})
	
	SET_TESTS_PROPERTIES(compare_${TEST_NAME} PROPERTIES DEPENDS run_${TEST_NAME}_Test})
	SET_TESTS_PROPERTIES(compare_${TEST_NAME} PROPERTIES ATTACHED_FILES_ON_FAIL ${OV_LOGFILE})
	
	LIST(REMOVE_AT TEST_SHRINKS 0)		
	LIST(REMOVE_AT TEST_TIKHONOVS 0)
	LIST(REMOVE_AT TEST_THRESHOLDS 0)

ENDFOREACH(TEST_NAME)


